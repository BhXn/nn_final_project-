{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP4e-s1SgTkj"
      },
      "source": [
        "# 神经网络编程框架\n",
        "- 参考配置：\n",
        "    - 系统：Ubuntu 20.04\n",
        "    - CUDA：12.4\n",
        "    - gcc：9.5\n",
        "    - cmake：4.0.1\n",
        "\n",
        "- 作业要求\n",
        "    1. 实现ppt中列举的TensorOp子类并测试；\n",
        "    2. 实现ppt中列举的Module、Optimizer、Scheduler子类；\n",
        "    3. 使用简易框架进行ResidualMLP实验，实现模型存储和读取，测试阶段不计算梯度。\n",
        "\n",
        "完成上述要求后可以通过以下代码进行测试"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LnEbqSDpgTkk",
        "outputId": "0e6fc356-8f6d-4836-a79f-46c2c687d56c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pybind11\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/243.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/243.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.13.6\n"
          ]
        }
      ],
      "source": [
        "#!pip3 install --upgrade --no-deps git+https://github.com/dlsys10714/mugrade.git\n",
        "!pip3 install pybind11"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/BhXn/nn_final_project-.git"
      ],
      "metadata": {
        "id": "RF7B4bXugp8s",
        "outputId": "f95ed6dc-2565-45a6-ccc1-563f141fa04d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nn_final_project-'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
            "remote: Total 131 (delta 21), reused 128 (delta 18), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (131/131), 3.99 MiB | 25.54 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "%cd nn"
      ],
      "metadata": {
        "id": "kOmw6lbog4zL",
        "outputId": "2a02b8cb-6277-4f6e-8e86-a2bdbb551784",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apps  CMakeLists.txt  main.ipynb  Makefile  python  README.md  src\n",
            "[Errno 2] No such file or directory: 'nn'\n",
            "/content/nn_final_project-/nn-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dp3WaYargTkk",
        "outputId": "7e3531b2-73e9-46b7-c04a-aa377cdf2de2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[33mCMake Warning (dev) at /usr/local/lib/python3.11/dist-packages/pybind11/share/cmake/pybind11/FindPythonLibsNew.cmake:101 (message):\n",
            "  Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
            "  are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
            "  the cmake_policy command to set the policy and suppress this warning, or\n",
            "  preferably upgrade to using FindPython, either by calling it explicitly\n",
            "  before pybind11, or by setting PYBIND11_FINDPYTHON ON before pybind11.\n",
            "Call Stack (most recent call first):\n",
            "  /usr/local/lib/python3.11/dist-packages/pybind11/share/cmake/pybind11/pybind11Tools.cmake:50 (find_package)\n",
            "  /usr/local/lib/python3.11/dist-packages/pybind11/share/cmake/pybind11/pybind11Common.cmake:228 (include)\n",
            "  /usr/local/lib/python3.11/dist-packages/pybind11/share/cmake/pybind11/pybind11Config.cmake:250 (include)\n",
            "  CMakeLists.txt:16 (find_package)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Found PythonInterp: /usr/bin/python3 (found suitable version \"3.11.13\", minimum required is \"3.7\")\n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.11.so\n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- Found pybind11: /usr/local/lib/python3.11/dist-packages/pybind11/include (found version \"2.13.6\")\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Found CUDA: /usr/local/cuda (found version \"12.5\")\n",
            "-- Found cuda, building cuda backend\n",
            "Sun Jun 29 11:51:52 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "-- Autodetected CUDA architecture(s):  7.5\n",
            "-- Configuring done (1.8s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/nn_final_project-/nn-project/build\n",
            "make[1]: Entering directory '/content/nn_final_project-/nn-project/build'\n",
            "make[2]: Entering directory '/content/nn_final_project-/nn-project/build'\n",
            "make[3]: Entering directory '/content/nn_final_project-/nn-project/build'\n",
            "make[3]: Leaving directory '/content/nn_final_project-/nn-project/build'\n",
            "make[3]: Entering directory '/content/nn_final_project-/nn-project/build'\n",
            "[ 25%] \u001b[32mBuilding CXX object CMakeFiles/ndarray_backend_cpu.dir/src/ndarray_backend_cpu.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX shared module /content/nn_final_project-/nn-project/python/needle/backend_ndarray/ndarray_backend_cpu.cpython-311-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/nn_final_project-/nn-project/build'\n",
            "[ 50%] Built target ndarray_backend_cpu\n",
            "make[3]: Entering directory '/content/nn_final_project-/nn-project/build'\n",
            "[ 75%] \u001b[34m\u001b[1mBuilding NVCC (Device) object CMakeFiles/ndarray_backend_cuda.dir/src/ndarray_backend_cuda_generated_ndarray_backend_cuda.cu.o\u001b[0m\n",
            "make[3]: Leaving directory '/content/nn_final_project-/nn-project/build'\n",
            "make[3]: Entering directory '/content/nn_final_project-/nn-project/build'\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module /content/nn_final_project-/nn-project/python/needle/backend_ndarray/ndarray_backend_cuda.cpython-311-x86_64-linux-gnu.so\u001b[0m\n",
            "make[3]: Leaving directory '/content/nn_final_project-/nn-project/build'\n",
            "[100%] Built target ndarray_backend_cuda\n",
            "make[2]: Leaving directory '/content/nn_final_project-/nn-project/build'\n",
            "make[1]: Leaving directory '/content/nn_final_project-/nn-project/build'\n"
          ]
        }
      ],
      "source": [
        "!make"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZHVMNaodgTkl",
        "outputId": "a821fd5a-edf7-4c5d-d831-e5eb200cb4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=./python\n",
            "env: NEEDLE_BACKEND=nd\n"
          ]
        }
      ],
      "source": [
        "%set_env PYTHONPATH ./python\n",
        "%set_env NEEDLE_BACKEND nd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vrt5XWkggTkl",
        "outputId": "88e6ba3c-1320-4b78-d042-e46821dbfc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Temp' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-21-4093496947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./python'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneedle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mndl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nn_final_project-/nn-project/./python/needle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nn_final_project-/nn-project/./python/needle/ops/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops_mathematic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops_logarithmic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mops_tuple\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/nn_final_project-/nn-project/./python/needle/ops/ops_mathematic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\"\"\"Operator implementations.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Temp' is not defined"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('./python')\n",
        "import needle as ndl\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x39lYXcagTkl"
      },
      "outputs": [],
      "source": [
        "如下是一些简单的测试样例，不报错即为通过作业要求中的1。其余部分请自行设计测试用例，确保代码的正确性。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7uCCJEigTkl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8iDg_rcgTkl"
      },
      "outputs": [],
      "source": [
        "#EWiseAdd\n",
        "def test_add():\n",
        "    np.testing.assert_allclose(ndl.add(np.array([1,2]), np.array([3,4])).numpy(),\n",
        "                               np.array([4,6]))\n",
        "test_add()\n",
        "#scalar_add\n",
        "def test_scalar_add():\n",
        "    np.testing.assert_allclose(ndl.add_scalar(np.array([1,2]), 3).numpy(),\n",
        "                               np.array([4,5]))\n",
        "test_scalar_add()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejlEgJrKgTkm"
      },
      "outputs": [],
      "source": [
        "def test_mul():\n",
        "    np.testing.assert_allclose(ndl.multiply(np.array([1,2]), np.array([3,4])).numpy(),\n",
        "                               np.array([3,8]))\n",
        "def test_scalar_mul():\n",
        "    np.testing.assert_allclose(ndl.mul_scalar(np.array([1,2]), 3).numpy(),\n",
        "                               np.array([3,6]))\n",
        "test_mul()\n",
        "test_scalar_mul()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUcVYNY7gTkm"
      },
      "outputs": [],
      "source": [
        "def test_power_scalar_forward():\n",
        "    print(ndl.power_scalar(ndl.Tensor(2),scalar=2).numpy())\n",
        "    print(ndl.power_scalar(ndl.Tensor([[0.5, 2.0, 3.0]]), scalar=2).numpy())\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.power_scalar(ndl.Tensor([[0.5, 2.0, 3.0]]), scalar=2).numpy(),\n",
        "        np.array([[0.25, 4.0, 9.0]]),\n",
        "    )\n",
        "test_power_scalar_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB9wfhSmgTkm"
      },
      "outputs": [],
      "source": [
        "def test_divide_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.divide(\n",
        "            ndl.Tensor([[3.3, 4.35, 1.2], [2.45, 0.95, 2.55]]),\n",
        "            ndl.Tensor([[4.6, 4.35, 4.8], [0.65, 0.7, 4.4]]),\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [\n",
        "                [0.717391304348, 1.0, 0.25],\n",
        "                [3.769230769231, 1.357142857143, 0.579545454545],\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "test_divide_forward()\n",
        "#scalerdiv\n",
        "def test_divide_scalar_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.divide_scalar(ndl.Tensor([[1.7, 1.45]]), scalar=12).numpy(),\n",
        "        np.array([[0.141666666667, 0.120833333333]]),\n",
        "    )\n",
        "test_divide_scalar_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTcKqOH6gTkm"
      },
      "outputs": [],
      "source": [
        "#transpose\n",
        "def test_transpose_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(ndl.Tensor([[[1.95]], [[2.7]], [[3.75]]]), axes=(1, 2)).numpy(),\n",
        "        np.array([[[1.95]], [[2.7]], [[3.75]]]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(\n",
        "            ndl.Tensor([[[[0.95]]], [[[2.55]]], [[[0.45]]]]), axes=(2, 3)\n",
        "        ).numpy(),\n",
        "        np.array([[[[0.95]]], [[[2.55]]], [[[0.45]]]]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(\n",
        "            ndl.Tensor(\n",
        "                [\n",
        "                    [[[0.4, 0.05], [2.95, 1.3]], [[4.8, 1.2], [1.65, 3.1]]],\n",
        "                    [[[1.45, 3.05], [2.25, 0.1]], [[0.45, 4.75], [1.5, 1.8]]],\n",
        "                    [[[1.5, 4.65], [1.35, 2.7]], [[2.0, 1.65], [2.05, 1.2]]],\n",
        "                ]\n",
        "            )\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [\n",
        "                [[[0.4, 2.95], [0.05, 1.3]], [[4.8, 1.65], [1.2, 3.1]]],\n",
        "                [[[1.45, 2.25], [3.05, 0.1]], [[0.45, 1.5], [4.75, 1.8]]],\n",
        "                [[[1.5, 1.35], [4.65, 2.7]], [[2.0, 2.05], [1.65, 1.2]]],\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(ndl.Tensor([[[2.45]], [[3.5]], [[0.9]]]), axes=(0, 1)).numpy(),\n",
        "        np.array([[[2.45], [3.5], [0.9]]]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(ndl.Tensor([[4.4, 2.05], [1.85, 2.25], [0.15, 1.4]])).numpy(),\n",
        "        np.array([[4.4, 1.85, 0.15], [2.05, 2.25, 1.4]]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(\n",
        "            ndl.Tensor([[0.05, 3.7, 1.35], [4.45, 3.25, 1.95], [2.45, 4.4, 4.5]])\n",
        "        ).numpy(),\n",
        "        np.array([[0.05, 4.45, 2.45], [3.7, 3.25, 4.4], [1.35, 1.95, 4.5]]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.transpose(\n",
        "            ndl.Tensor(\n",
        "                [\n",
        "                    [[0.55, 1.8, 0.2], [0.8, 2.75, 3.7], [0.95, 1.4, 0.8]],\n",
        "                    [[0.75, 1.6, 1.35], [3.75, 4.0, 4.55], [1.85, 2.5, 4.8]],\n",
        "                    [[0.2, 3.35, 3.4], [0.3, 4.85, 4.85], [4.35, 4.25, 3.05]],\n",
        "                ]\n",
        "            ),\n",
        "            axes=(0, 1),\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [\n",
        "                [[0.55, 1.8, 0.2], [0.75, 1.6, 1.35], [0.2, 3.35, 3.4]],\n",
        "                [[0.8, 2.75, 3.7], [3.75, 4.0, 4.55], [0.3, 4.85, 4.85]],\n",
        "                [[0.95, 1.4, 0.8], [1.85, 2.5, 4.8], [4.35, 4.25, 3.05]],\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "test_transpose_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCFG-IHvgTkn"
      },
      "outputs": [],
      "source": [
        "def test_reshape_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.reshape(\n",
        "            ndl.Tensor(\n",
        "                [\n",
        "                    [2.9, 2.0, 2.4],\n",
        "                    [3.95, 3.95, 4.65],\n",
        "                    [2.1, 2.5, 2.7],\n",
        "                    [1.9, 4.85, 3.25],\n",
        "                    [3.35, 3.45, 3.45],\n",
        "                ]\n",
        "            ),\n",
        "            shape=(15,),\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [\n",
        "                2.9,\n",
        "                2.0,\n",
        "                2.4,\n",
        "                3.95,\n",
        "                3.95,\n",
        "                4.65,\n",
        "                2.1,\n",
        "                2.5,\n",
        "                2.7,\n",
        "                1.9,\n",
        "                4.85,\n",
        "                3.25,\n",
        "                3.35,\n",
        "                3.45,\n",
        "                3.45,\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.reshape(\n",
        "            ndl.Tensor(\n",
        "                [\n",
        "                    [[4.1, 4.05, 1.35, 1.65], [3.65, 0.9, 0.65, 4.15]],\n",
        "                    [[4.7, 1.4, 2.55, 4.8], [2.8, 1.75, 2.8, 0.6]],\n",
        "                    [[3.75, 0.6, 0.0, 3.5], [0.15, 1.9, 4.75, 2.8]],\n",
        "                ]\n",
        "            ),\n",
        "            shape=(2, 3, 4),\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [\n",
        "                [\n",
        "                    [4.1, 4.05, 1.35, 1.65],\n",
        "                    [3.65, 0.9, 0.65, 4.15],\n",
        "                    [4.7, 1.4, 2.55, 4.8],\n",
        "                ],\n",
        "                [[2.8, 1.75, 2.8, 0.6], [3.75, 0.6, 0.0, 3.5], [0.15, 1.9, 4.75, 2.8]],\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "test_reshape_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwxpSOZMgTkn"
      },
      "outputs": [],
      "source": [
        "def test_broadcast_to_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.broadcast_to(ndl.Tensor([[1.85, 0.85, 0.6]]), shape=(3, 3, 3)).numpy(),\n",
        "        np.array(\n",
        "            [\n",
        "                [[1.85, 0.85, 0.6], [1.85, 0.85, 0.6], [1.85, 0.85, 0.6]],\n",
        "                [[1.85, 0.85, 0.6], [1.85, 0.85, 0.6], [1.85, 0.85, 0.6]],\n",
        "                [[1.85, 0.85, 0.6], [1.85, 0.85, 0.6], [1.85, 0.85, 0.6]],\n",
        "            ]\n",
        "        ),\n",
        "    )\n",
        "test_broadcast_to_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhf6gJXqgTkn"
      },
      "outputs": [],
      "source": [
        "def test_summation_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.summation(\n",
        "            ndl.Tensor(\n",
        "                [\n",
        "                    [2.2, 4.35, 1.4, 0.3, 2.65],\n",
        "                    [1.0, 0.85, 2.75, 3.8, 1.55],\n",
        "                    [3.2, 2.3, 3.45, 0.7, 0.0],\n",
        "                ]\n",
        "            )\n",
        "        ).numpy(),\n",
        "        np.array(30.5),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.summation(\n",
        "            ndl.Tensor(\n",
        "                [\n",
        "                    [1.05, 2.55, 1.0],\n",
        "                    [2.95, 3.7, 2.6],\n",
        "                    [0.1, 4.1, 3.3],\n",
        "                    [1.1, 3.4, 3.4],\n",
        "                    [1.8, 4.55, 2.3],\n",
        "                ]\n",
        "            ),\n",
        "            axes=1,\n",
        "        ).numpy(),\n",
        "        np.array([4.6, 9.25, 7.5, 7.9, 8.65]),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.summation(\n",
        "            ndl.Tensor([[1.5, 3.85, 3.45], [1.35, 1.3, 0.65], [2.6, 4.55, 0.25]]),\n",
        "            axes=0,\n",
        "        ).numpy(),\n",
        "        np.array([5.45, 9.7, 4.35]),\n",
        "    )\n",
        "test_summation_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUI05TKTgTkn"
      },
      "outputs": [],
      "source": [
        "def test_matmul_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.matmul(\n",
        "            ndl.Tensor([[4.95, 1.75, 0.25], [4.15, 4.25, 0.3], [0.3, 0.4, 2.1]]),\n",
        "            ndl.Tensor([[1.35, 2.2, 1.55], [3.85, 4.8, 2.6], [1.15, 0.85, 4.15]]),\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [[13.7075, 19.5025, 13.26], [22.31, 29.785, 18.7275], [4.36, 4.365, 10.22]]\n",
        "        ),\n",
        "    )\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.matmul(\n",
        "            ndl.Tensor([[3.8, 0.05], [2.3, 3.35], [1.6, 2.6]]),\n",
        "            ndl.Tensor([[1.1, 3.5, 3.7], [0.05, 1.25, 1.0]]),\n",
        "        ).numpy(),\n",
        "        np.array(\n",
        "            [[4.1825, 13.3625, 14.11], [2.6975, 12.2375, 11.86], [1.89, 8.85, 8.52]]\n",
        "        ),\n",
        "    )\n",
        "test_matmul_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ_fz7DEgTkn"
      },
      "outputs": [],
      "source": [
        "def test_negate_forward():\n",
        "    np.testing.assert_allclose(\n",
        "        ndl.negate(ndl.Tensor([[1.45, 0.55]])).numpy(), np.array([[-1.45, -0.55]])\n",
        "    )\n",
        "test_negate_forward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tTZ5AuigTkn"
      },
      "outputs": [],
      "source": [
        "#求导\n",
        "def test_compute_gradient():\n",
        "    gradient_check(\n",
        "        lambda A, B, C: ndl.summation((A @ B + C) * (A @ B), axes=None),\n",
        "        ndl.Tensor(np.random.randn(10, 9)),\n",
        "        ndl.Tensor(np.random.randn(9, 8)),\n",
        "        ndl.Tensor(np.random.randn(10, 8)),\n",
        "        backward=True,\n",
        "    )\n",
        "    gradient_check(\n",
        "        lambda A, B: ndl.summation(ndl.broadcast_to(A, shape=(10, 9)) * B, axes=None),\n",
        "        ndl.Tensor(np.random.randn(10, 1)),\n",
        "        ndl.Tensor(np.random.randn(10, 9)),\n",
        "        backward=True,\n",
        "    )\n",
        "    gradient_check(\n",
        "        lambda A, B, C: ndl.summation(\n",
        "            ndl.reshape(A, shape=(10, 10)) @ B / 5 + C, axes=None\n",
        "        ),\n",
        "        ndl.Tensor(np.random.randn(100)),\n",
        "        ndl.Tensor(np.random.randn(10, 5)),\n",
        "        ndl.Tensor(np.random.randn(10, 5)),\n",
        "        backward=True,\n",
        "    )\n",
        "\n",
        "    # check gradient of gradient\n",
        "    x2 = ndl.Tensor([6])\n",
        "    x3 = ndl.Tensor([0])\n",
        "    y = x2 * x2 + x2 * x3\n",
        "    y.backward()\n",
        "    grad_x2 = x2.grad\n",
        "    grad_x3 = x3.grad\n",
        "    # gradient of gradient\n",
        "    grad_x2.backward()\n",
        "    grad_x2_x2 = x2.grad\n",
        "    grad_x2_x3 = x3.grad\n",
        "    x2_val = x2.numpy()\n",
        "    x3_val = x3.numpy()\n",
        "    assert y.numpy() == x2_val * x2_val + x2_val * x3_val\n",
        "    assert grad_x2.numpy() == 2 * x2_val + x3_val\n",
        "    assert grad_x3.numpy() == x2_val\n",
        "    assert grad_x2_x2.numpy() == 2\n",
        "    assert grad_x2_x3.numpy() == 1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}